{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from ipywidgets import widgets\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load sim_functions.py\n",
    "# sim_functions.py\n",
    "# Frank Mei, Lisa Jian, Michael Jetsupphasuk, My Dinh\n",
    "# 04 December, 2017\n",
    "# Functions to simulate lag-adjusted Spearman's rank correlation test for earthquakes\n",
    "\n",
    "\"\"\"\n",
    "Context: \n",
    "\n",
    "Fill me in!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def largest_corr(rank1, rank2, lag=12, norm=np.inf):\n",
    "    \"\"\"\n",
    "    Given two ranked vectors, take a window of length n-12,\n",
    "    get a list of lag correlations by shifting the second rank vector,\n",
    "    return the p-norm correlation in the list (default is maximum correlation).\n",
    "\n",
    "    For special case of one list containing all same value (e.g. [1,1,1]), the\n",
    "    correlation will equal one from a divide by 0 error (since sd is 0). For\n",
    "    these cases, correlation is coerced to 0.\n",
    "    \"\"\"\n",
    "\n",
    "    r1 = rank1[:-12]\n",
    "    corrs = list(map(lambda i: pearsonr(r1, rank2[i:(len(r1)+i)])[0], range(lag+1)))\n",
    "    corrs = [0 if math.isnan(cor) else cor for cor in corrs]\n",
    "    # return np.argmax(corrs) # which lag has the maximum correlation\n",
    "    return np.linalg.norm(corrs, ord=norm)\n",
    "\n",
    "\n",
    "def simulate(ranks1, ranks2, num_trials=10000, lag=12, norm=np.inf):\n",
    "    \"\"\"\n",
    "    Given two ranked vectors, repeatedly permute ranks1 and get the \n",
    "    p-norm correlation for all lags specified. Return all simulated values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Used to simulate a single trial. The input is not used.\n",
    "    def simulate_single_trial(_):\n",
    "        np.random.shuffle(ranks1)\n",
    "        return largest_corr(ranks1, ranks2, lag, norm)\n",
    "    \n",
    "    # Make a copy for ranks1 because np.random.shuffle is in place.\n",
    "    ranks1 = ranks1.copy()\n",
    "\n",
    "    return np.array(list(map(simulate_single_trial, range(num_trials))))\n",
    "\n",
    "\n",
    "def simulate_by_block(ranks1, ranks2, bstart, bsize, lag=12, norm=np.inf, num_trials=10000):\n",
    "    \"\"\"\n",
    "    Like `simulate` above except permutes by block specified by `bstart`\n",
    "    and `bsize`.\n",
    "    \"\"\"\n",
    "\n",
    "    def simulate_block_trial(_):\n",
    "        r1, end = block_permute(ranks1, bstart, bsize)\n",
    "        r2 = ranks2.copy()[bstart : end]\n",
    "        return largest_corr(r1, r2, lag, norm)\n",
    "\n",
    "    # Make a copy for ranks1 because block_permute is in place.\n",
    "    ranks1 = ranks1.copy()\n",
    "\n",
    "    return np.array(list(map(simulate_block_trial, range(num_trials))))\n",
    "\n",
    "\n",
    "def p_value(dist, observed):\n",
    "    \"\"\"\n",
    "    Given an empirical distribution `dist`, this function returns the\n",
    "    probability of seeing `observed` or larger (i.e. this is one-sided).\n",
    "    The empirical `dist`, for instance, would look like the return of\n",
    "    the `simulate` function above.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sum(dist >= observed) / float(len(dist))\n",
    "\n",
    "\n",
    "def corr_test(lst1, lst2, lag=12, norm=np.inf, bstart=0, bsize=6, plot=True):\n",
    "    \"\"\"\n",
    "    Combining simulation into a test that returns a p-value. Option\n",
    "    to plot.\n",
    "    \"\"\"\n",
    "\n",
    "    og = largest_corr(lst1, lst2, lag, norm)\n",
    "    s = simulate_by_block(lst1, lst2, lag=lag, norm=norm, bstart=bstart, bsize=bsize)\n",
    "    if plot:\n",
    "        plt.hist(s, bins = 'auto')\n",
    "        plt.axvline(x = og, color = 'red')\n",
    "        plt.show()\n",
    "    return p_value(s, og)\n",
    "\n",
    "\n",
    "def block_permute(ts, start, length): \n",
    "    \"\"\"\n",
    "    Each block is defined by the start point of to begin blocking and length of the block. \n",
    "    The possible starting points have to be from beginining to the length of the block. \n",
    "    If it starts in the middle and the n - l points aren't the multiple of length of the block,\n",
    "    cut off the start and the end of the array\n",
    "\n",
    "    Args:\n",
    "        ts      (1D np.array) : Rank time series (e.g. earthquakes, water)\n",
    "        start   (int)         : Start point of the block \n",
    "        length  (int)         : Length of the block \n",
    "        \n",
    "    Returns:\n",
    "        1D Array permuted block of time\n",
    "        endpoint of cutoff vector\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    assert np.any(ts[:length] == ts[start]), \\\n",
    "        \"Starting point of the block is too far.\"\n",
    "\n",
    "    assert length < len(ts), \\\n",
    "    \"Block size too big\"\n",
    "\n",
    "    nb_blocks = np.floor((len(ts) - len(ts[: (start + length)])) / length + 1)\n",
    "    assert nb_blocks > 1, \"block size is too big\"\n",
    "    end = int(start + nb_blocks*length)\n",
    "\n",
    "    shuffle_ts = ts[start:end].copy()\n",
    "    shuffle_blocks = shuffle_ts.reshape(len(shuffle_ts)//length, length)\n",
    "    np.random.shuffle(shuffle_blocks)\n",
    "    return shuffle_blocks.ravel(), end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load get_eq.py\n",
    "# get_eq.py\n",
    "# Frank Mei, Lisa Jian, Michael Jetsupphasuk, My Dinh\n",
    "# 04 December, 2017\n",
    "# Earthquake generating functions.\n",
    "\n",
    "\"\"\"\n",
    "Context: \n",
    "\n",
    "Fill me in!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_eq_simple(water, mu=0.0000001, beta=0.00001):\n",
    "    \"\"\"\n",
    "    Simulates earthquake data with a poisson process with a dependency on water at lag 0.\n",
    "    \"\"\"\n",
    "\n",
    "    eq = np.array([np.random.poisson(np.exp(np.random.randn(1)) * (mu + beta * water[i])) \n",
    "                   for i in range(len(water))])\n",
    "    return eq\n",
    "\n",
    "\n",
    "def get_eq_timelag(water, mu=0.0000001, beta=0.00001, alpha=0.047):\n",
    "    \"\"\"\n",
    "    Simulates earthquake data with a poisson process with a dependency on water at lag 0.\n",
    "    Also includes a dependency on previous earthquake data.\n",
    "    \"\"\"\n",
    "\n",
    "    eq = np.random.poisson(np.exp(np.random.randn(1)) * (mu + beta * water[0]))\n",
    "    for i in range(1, len(water)):\n",
    "        new = np.random.poisson(np.exp(np.random.randn(1)) * (mu + beta * water[i]) \\\n",
    "                                + np.exp(np.random.randn(1)) * alpha * eq[i-1])\n",
    "        eq = np.concatenate([eq, new])\n",
    "    return eq\n",
    "\n",
    "\n",
    "def get_eq(water, mu=0.0000001, alpha=0.047, betas=[0.0000006, 0.0000006, 0.0000007, 0.0000009, 0.00001]):\n",
    "    \"\"\"\n",
    "    Simulates earthquake data with a poisson process with a dependency on water at lag 0-4.\n",
    "    Also includes a dependency on previous earthquake data.\n",
    "    \"\"\"\n",
    "\n",
    "    eq = np.random.poisson(np.exp(np.random.randn(1)) * (mu + betas[4] * water[0]))\n",
    "    for i in range(1, len(water)):\n",
    "        if i < 4:\n",
    "            new = np.random.poisson(np.exp(np.random.randn(1)) * (mu + betas[4] * water[i]) + \\\n",
    "                                    np.exp(np.random.randn(1)) * alpha * eq[i-1])\n",
    "        else:\n",
    "            new = np.random.poisson(np.exp(np.random.randn(1)) * (mu + \\\n",
    "                                                                 np.random.uniform(1) * betas[4] * water[i] + \\\n",
    "                                                                 np.random.uniform(1) * betas[3] * water[i-1] + \\\n",
    "                                                                 np.random.uniform(1) * betas[2] * water[i-2] + \\\n",
    "                                                                 np.random.uniform(1) * betas[1] * water[i-3] + \\\n",
    "                                                                 np.random.uniform(1) * betas[0] * water[i-4]) + \\\n",
    "                                    np.exp(np.random.randn(1)) * alpha * eq[i-1])\n",
    "\n",
    "        eq = np.concatenate([eq, new])\n",
    "    return eq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messing with interactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "water = []\n",
    "with open('../data/final_water.csv') as file:\n",
    "    f = csv.reader(file, delimiter = ',')\n",
    "    next(f)\n",
    "    for row in f:\n",
    "        row = [float(r) for r in row]\n",
    "        water.append(row)\n",
    "\n",
    "# pick a random grid to take water injection from\n",
    "# random.seed(157157)\n",
    "random_water = random.sample(range(len(water)), 1)[0]\n",
    "use_water = np.array(water[random_water])\n",
    "water_rank = rankdata(use_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(mu_order, alpha, b0, b1, b2, b3, b4, max_lag, norm):\n",
    "    mu = 10 ** mu_order\n",
    "    betas = np.array([b0, b1, b2, b3, b4]) * 0.0000001\n",
    "    norm = float(norm)\n",
    "    eqs = get_eq(use_water, mu, alpha, betas)\n",
    "    eqs_rank = rankdata(eqs)\n",
    "    pval = corr_test(water_rank, eqs_rank, max_lag, norm, plot = True)\n",
    "    print(\"p-val:\", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.fun>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widgets.interact_manual(fun, mu_order = (-7, 0, 1), alpha = (0.0, 0.5, 0.01), b0=(1, 9), b1=(1, 9), b2=(1, 9), b3=(1, 9), b4=(1, 9), max_lag=(6, 18), norm=[1, 2, 4, np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "a82573b8163449b9a3574fd48fde7cfd": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
